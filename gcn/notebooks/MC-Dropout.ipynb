{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GDN with MC-Dropout\n",
    "Gal et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import pdb\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Add higher directory to python modules path.\n",
    "sys.path.append(\"..\") \n",
    "from dataloader import load_cora\n",
    "from model import GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class obj(object):\n",
    "    def __init__(self, d):\n",
    "        for a, b in d.items():\n",
    "            if isinstance(b, (list, tuple)):\n",
    "               setattr(self, a, [obj(x) if isinstance(x, dict) else x for x in b])\n",
    "            else:\n",
    "               setattr(self, a, obj(b) if isinstance(b, dict) else b)\n",
    "args = {\n",
    "    'gpu': 1,\n",
    "    'seed': None,\n",
    "    'epochs': 500,\n",
    "    'lr': 0.01,\n",
    "    'wd': 5e-4,\n",
    "    'layers': 2,\n",
    "    'h_size': 16,\n",
    "    'dropout': 0.5,\n",
    "    'val_every': -1,\n",
    "    'val_only': 1,\n",
    "    'checkpoint': 0, \n",
    "    'model': '../save/model-val-0.8233.pth', \n",
    "    'log_every': 50,\n",
    "    'prepro': '../../data/cora/preprocessed.pth',\n",
    "    'test': 0,\n",
    "}\n",
    "args = obj(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "start = time.time()\n",
    "args.gpu = args.gpu and torch.cuda.is_available() and False\n",
    "if args.seed is not None:\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    if args.cuda:\n",
    "        torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "# Data\n",
    "if args.prepro:\n",
    "    tmp = torch.load(args.prepro)\n",
    "    adj_i, adj_v, adj_s, feats, labels, idx_train, idx_val, idx_test = tmp\n",
    "    adj = torch.sparse.FloatTensor(adj_i, adj_v, adj_s)\n",
    "else:\n",
    "    adj, feats, labels, idx_train, idx_val, idx_test = load_cora()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = GCN(num_layers=args.layers, \n",
    "            in_size=feats.shape[1],\n",
    "            h_size=args.h_size, \n",
    "            out_size=labels.max().item() + 1,\n",
    "            dropout=args.dropout,\n",
    "            mc_dropout=True)\n",
    "if args.model:\n",
    "    model.load_state_dict(torch.load(args.model))\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.wd)\n",
    "\n",
    "# GPU\n",
    "if args.gpu:\n",
    "    tmp = model, adj, feats, labels, idx_train, idx_val, idx_test\n",
    "    tmp = [x.cuda() for x in tmp]\n",
    "    model, adj, feats, labels, idx_train, idx_val, idx_test = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.753333330154419\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F \n",
    "\n",
    "# Data for validation/plotting \n",
    "idx = idx_val #torch.cat((idx_val, idx_test))\n",
    "\n",
    "# Validation: average over samples\n",
    "model.eval()\n",
    "total_preds = 0\n",
    "num_samples = 100\n",
    "for i in range(num_samples):\n",
    "    output = model(feats, adj)\n",
    "    y_hat, y = (output[idx], labels[idx]) # helper\n",
    "    loss = F.cross_entropy(y_hat, y)\n",
    "    total_preds += preds\n",
    "preds = total_preds / num_samples\n",
    "preds = y_hat.max(1)[1].type_as(y)\n",
    "preds_eq = preds.eq(y)\n",
    "acc = preds_eq.float().sum() / len(y)\n",
    "print(acc.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.8375487923622131\n"
     ]
    }
   ],
   "source": [
    "print(-loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring\n",
    "We explore the degree of uncertainty given to the incorrectly labeled data points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract incorrect labels\n",
    "y_hat_wrong = torch.nn.functional.softmax(output[idx][preds_eq == 0], dim=1)\n",
    "y_wrong = labels[idx][preds_eq == 0]\n",
    "y_wrong_onehot = torch.eye(7)[labels[idx][preds_eq == 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Example 53\n",
      "Prediction:  [0.21022612 0.10971968 0.19391564 0.20956302 0.20058776 0.02863739\n",
      " 0.04735033]\n",
      "Label:  2\n",
      "\n",
      "--- Example 33\n",
      "Prediction:  [0.31988177 0.06028238 0.08148964 0.25225142 0.10844477 0.15625136\n",
      " 0.02139865]\n",
      "Label:  3\n"
     ]
    }
   ],
   "source": [
    "# Some example data points\n",
    "print('--- Example 53')\n",
    "print('Prediction: ', y_hat_wrong[53].data.numpy())\n",
    "print('Label: ', y_wrong[53].item())\n",
    "print()\n",
    "print('--- Example 33')\n",
    "print('Prediction: ', y_hat_wrong[33].data.numpy())\n",
    "print('Label: ', y_wrong[33].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The amount we are wrong for each example: \n",
    "# max predicted (wrong) class probability - the correct class probability\n",
    "amt_wrong = y_hat_wrong.max(dim=1)[0] - (y_wrong_onehot * y_hat_wrong).sum(dim=1)\n",
    "plt.hist(amt_wrong.detach().cpu().numpy(), bins=20)\n",
    "plt.xlim(0.0,1.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
