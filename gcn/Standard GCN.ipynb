{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard GCN\n",
    "As in Kipf et al. (2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import pdb\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Add higher directory to python modules path.\n",
    "sys.path.append(\"..\") \n",
    "from dataloader import load_cora\n",
    "from model import GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "class obj(object):\n",
    "    def __init__(self, d):\n",
    "        for a, b in d.items():\n",
    "            if isinstance(b, (list, tuple)):\n",
    "               setattr(self, a, [obj(x) if isinstance(x, dict) else x for x in b])\n",
    "            else:\n",
    "               setattr(self, a, obj(b) if isinstance(b, dict) else b)\n",
    "args = {\n",
    "    'gpu': 1,\n",
    "    'seed': None,\n",
    "    'epochs': 500,\n",
    "    'lr': 0.01,\n",
    "    'wd': 5e-4,\n",
    "    'layers': 2,\n",
    "    'h_size': 16,\n",
    "    'dropout': 0.5,\n",
    "    'val_every': -1,\n",
    "    'val_only': 1,\n",
    "    'checkpoint': 0,\n",
    "    'model': 'save/model-val-0.8233.pth',\n",
    "    'log_every': 50,\n",
    "    'prepro': '../data/cora/preprocessed.pth',\n",
    "    'test': 0,\n",
    "}\n",
    "args = obj(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_to_sparse(x):\n",
    "    indices = torch.nonzero(x).t()\n",
    "    values = x[indices[0], indices[1]] # modify this based on dimensionality\n",
    "    return torch.sparse.FloatTensor(indices, values, x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "start = time.time()\n",
    "args.gpu = args.gpu and torch.cuda.is_available() and False\n",
    "if args.seed is not None:\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    if args.cuda:\n",
    "        torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "# Data\n",
    "if args.prepro:\n",
    "    tmp = torch.load(args.prepro)\n",
    "    adj_i, adj_v, adj_s, feats, labels, idx_train, idx_val, idx_test = tmp\n",
    "    adj = torch.sparse.FloatTensor(adj_i, adj_v, adj_s)\n",
    "else:\n",
    "    adj, feats, labels, idx_train, idx_val, idx_test = load_cora()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = GCN(num_layers=args.layers, \n",
    "            in_size=feats.shape[1],\n",
    "            h_size=args.h_size, \n",
    "            out_size=labels.max().item() + 1,\n",
    "            dropout=args.dropout)\n",
    "if args.model:\n",
    "    model.load_state_dict(torch.load(args.model))\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.wd)\n",
    "\n",
    "# GPU\n",
    "if args.gpu:\n",
    "    tmp = model, adj, feats, labels, idx_train, idx_val, idx_test\n",
    "    tmp = [x.cuda() for x in tmp]\n",
    "    model, adj, feats, labels, idx_train, idx_val, idx_test = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8350)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F \n",
    "\n",
    "# Data for validation/plotting \n",
    "idx = idx_test #torch.cat((idx_val, idx_test))\n",
    "\n",
    "# Validation\n",
    "model.eval()\n",
    "output = model(feats, adj)\n",
    "y_hat, y = (output[idx], labels[idx]) # helper\n",
    "loss = F.cross_entropy(y_hat, y)\n",
    "preds = y_hat.max(1)[1].type_as(y)\n",
    "preds_eq = preds.eq(y)\n",
    "acc = preds_eq.float().sum() / len(y)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Out-of-distribution nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 0, M = 0 76.5726% 0.7395% 5.1937% 4.4274% 4.1639% 1.7721% 7.1308%\n",
      "N = 0, M = 1 70.6429% 1.4274% 6.4455% 5.5714% 5.3901% 2.2954% 8.2272%\n",
      "N = 0, M = 2 72.7287% 0.8991% 7.6879% 4.9473% 4.7004% 1.8096% 7.2269%\n",
      "N = 0, M = 3 74.4290% 0.9043% 5.9769% 5.3576% 4.6091% 1.9038% 6.8193%\n",
      "N = 0, M = 4 73.1551% 0.8928% 5.5551% 4.4327% 6.9225% 2.0811% 6.9606%\n",
      "N = 0, M = 5 69.6398% 1.0416% 5.8872% 4.7697% 5.2305% 3.4001% 10.0310%\n",
      "N = 0, M = 6 71.6601% 0.8215% 5.3034% 3.8787% 4.0205% 2.4140% 11.9017%\n",
      "N = 1, M = 0 1.6594% 78.2408% 2.7569% 5.6561% 4.8984% 5.0243% 1.7640%\n",
      "N = 1, M = 1 1.0862% 82.9628% 2.1483% 4.5343% 4.0766% 3.9051% 1.2867%\n",
      "N = 1, M = 2 1.4679% 79.0729% 3.1960% 5.5558% 4.8511% 4.3062% 1.5502%\n",
      "N = 1, M = 3 1.4440% 79.4284% 2.7122% 5.7547% 4.5590% 4.5894% 1.5123%\n",
      "N = 1, M = 4 1.4051% 78.4183% 2.5517% 4.6844% 6.3885% 4.9726% 1.5794%\n",
      "N = 1, M = 5 1.2974% 78.1030% 2.3662% 4.8179% 4.8892% 6.6892% 1.8372%\n",
      "N = 1, M = 6 1.5605% 77.4957% 2.6160% 4.9852% 4.8505% 6.0203% 2.4717%\n",
      "N = 2, M = 0 10.1696% 2.7337% 71.0409% 6.5952% 4.8072% 2.0084% 2.6449%\n",
      "N = 2, M = 1 8.4542% 4.0908% 70.6223% 7.0317% 5.1437% 2.1081% 2.5492%\n",
      "N = 2, M = 2 7.7004% 2.4216% 76.2982% 5.4975% 4.3529% 1.6187% 2.1107%\n",
      "N = 2, M = 3 9.0661% 2.9379% 71.8245% 6.9801% 4.9078% 1.9388% 2.3447%\n",
      "N = 2, M = 4 8.7654% 2.9043% 70.8986% 6.0759% 6.8889% 2.2120% 2.2548%\n",
      "N = 2, M = 5 8.4162% 3.1431% 70.2754% 6.2218% 5.4500% 3.2867% 3.2068%\n",
      "N = 2, M = 6 9.4790% 2.8637% 70.6126% 5.8958% 4.4004% 2.6474% 4.1011%\n",
      "N = 3, M = 0 20.8794% 8.3662% 11.8341% 44.7199% 7.0826% 5.0899% 2.0279%\n",
      "N = 3, M = 1 16.0849% 12.5034% 12.0190% 45.2913% 7.0325% 5.1540% 1.9149%\n",
      "N = 3, M = 2 17.6840% 8.9425% 15.6975% 43.7847% 7.3689% 4.6939% 1.8285%\n",
      "N = 3, M = 3 18.1418% 8.9337% 12.1332% 47.2987% 6.9237% 4.8304% 1.7386%\n",
      "N = 3, M = 4 19.1741% 8.9157% 12.5365% 41.4326% 10.6697% 5.4276% 1.8438%\n",
      "N = 3, M = 5 17.1805% 9.9735% 12.1568% 42.4047% 7.6242% 8.2265% 2.4338%\n",
      "N = 3, M = 6 20.3778% 9.3754% 12.4103% 40.7904% 6.8536% 6.8386% 3.3539%\n",
      "N = 4, M = 0 4.1875% 1.4439% 2.8461% 1.3142% 85.5102% 3.7944% 0.9037%\n",
      "N = 4, M = 1 3.2869% 2.1223% 2.8561% 1.2823% 85.5566% 4.0145% 0.8813%\n",
      "N = 4, M = 2 3.4571% 1.4668% 3.6092% 1.2379% 85.8748% 3.5648% 0.7894%\n",
      "N = 4, M = 3 3.8658% 1.5705% 3.0550% 1.4351% 85.4623% 3.7979% 0.8135%\n",
      "N = 4, M = 4 2.7905% 1.1123% 2.1776% 0.8560% 89.5329% 2.8923% 0.6384%\n",
      "N = 4, M = 5 3.1205% 1.6224% 2.7835% 1.1342% 84.5020% 5.7690% 1.0684%\n",
      "N = 4, M = 6 3.7651% 1.5682% 2.8087% 1.1105% 84.1243% 5.1694% 1.4538%\n",
      "N = 5, M = 0 0.5271% 0.9154% 0.5106% 0.4375% 1.1662% 91.5420% 4.9012%\n",
      "N = 5, M = 1 0.4004% 1.2250% 0.4832% 0.4069% 1.1604% 91.7586% 4.5655%\n",
      "N = 5, M = 2 0.4679% 0.9729% 0.6815% 0.4277% 1.2728% 91.3772% 4.8000%\n",
      "N = 5, M = 3 0.4895% 0.9960% 0.5381% 0.4720% 1.2001% 91.8359% 4.4684%\n",
      "N = 5, M = 4 0.4318% 0.9032% 0.4887% 0.3611% 1.5546% 91.8628% 4.3979%\n",
      "N = 5, M = 5 0.2900% 0.7280% 0.3590% 0.2696% 0.8816% 93.5670% 3.9047%\n",
      "N = 5, M = 6 0.3935% 0.7863% 0.4244% 0.2976% 0.9442% 91.3843% 5.7698%\n",
      "N = 6, M = 0 4.7434% 0.5276% 0.9678% 0.3081% 0.5507% 4.1927% 88.7096%\n",
      "N = 6, M = 1 4.0711% 0.7631% 1.0109% 0.3359% 0.6403% 4.5633% 88.6154%\n",
      "N = 6, M = 2 4.5167% 0.6046% 1.3346% 0.3442% 0.6050% 4.3721% 88.2228%\n",
      "N = 6, M = 3 4.7364% 0.6394% 1.1298% 0.3699% 0.6154% 4.5877% 87.9214%\n",
      "N = 6, M = 4 4.3336% 0.6175% 0.9804% 0.2949% 0.8645% 5.1337% 87.7754%\n",
      "N = 6, M = 5 3.5322% 0.5352% 0.8680% 0.2585% 0.5805% 5.6672% 88.5583%\n",
      "N = 6, M = 6 3.3431% 0.3996% 0.7020% 0.2011% 0.4054% 3.7149% 91.2339%\n"
     ]
    }
   ],
   "source": [
    "# Loop over classes\n",
    "for n in range(7): # neighbor class\n",
    "    for m in range(7): # center node class\n",
    "        \n",
    "        # Create connections to nodes\n",
    "        adj_vec =  torch.eye(adj.shape[0])[(labels == n).nonzero()[0:5]].sum(dim=0).squeeze() # 5 from class 5\n",
    "        adj_vec = torch.cat((adj_vec, torch.ones(1)))\n",
    "        adj_vec = (adj_vec / adj_vec.sum()).reshape(-1,1)\n",
    "\n",
    "        # Modify adjacency matrix\n",
    "        adj_ood = adj.to_dense()\n",
    "        adj_ood = torch.cat((torch.cat((adj_ood, adj_vec[:-1]), dim=1), adj_vec.t()), dim=0)\n",
    "        adj_ood = dense_to_sparse(adj_ood)\n",
    "\n",
    "        # Features\n",
    "        feats_ood = torch.cat((feats, feats[labels == m].mean(dim=0, keepdim=True)), dim=0)\n",
    "        \n",
    "        # Print prediction\n",
    "        probs = torch.softmax(model(feats_ood, adj_ood), dim=1)[-1]\n",
    "        l = list(probs.detach().numpy())\n",
    "        l = ' '.join(['{:.4f}%'.format(x * 100) for x in l])\n",
    "        print('N = {}, M = {}'.format(n, m), l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0189, 0.6358, 0.0405, 0.0607, 0.0672, 0.1472, 0.0297],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 1433])"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_feats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring\n",
    "We explore the degree of uncertainty given to the incorrectly labeled data points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (8, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract incorrect labels\n",
    "y_hat_wrong = torch.nn.functional.softmax(output[idx][preds_eq == 0], dim=1)\n",
    "y_hat_right = torch.nn.functional.softmax(output[idx][preds_eq == 1], dim=1)\n",
    "# y_wrong = labels[idx][preds_eq == 0]\n",
    "#y_wrong_onehot = torch.eye(7)[labels[idx][preds_eq == 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Some example data points\n",
    "# print('--- Example 53')\n",
    "# print('Prediction: ', y_hat_wrong[53].data.numpy())\n",
    "# print('Label: ', y_wrong[53].item())\n",
    "# print()\n",
    "# print('--- Example 33')\n",
    "# print('Prediction: ', y_hat_wrong[33].data.numpy())\n",
    "# print('Label: ', y_wrong[33].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The amount we are wrong for each example: \n",
    "# max predicted (wrong) class probability - the correct class probability\n",
    "# amt_wrong = y_hat_wrong.max(dim=1)[0] - (y_wrong_onehot * y_hat_wrong).sum(dim=1)\n",
    "\n",
    "entropy_wrong = -(y_hat_wrong * torch.log(y_hat_wrong)).sum(dim=1)\n",
    "entropy_right = -(y_hat_right * torch.log(y_hat_right)).sum(dim=1)\n",
    "plt.hist(entropy_right.detach().cpu().numpy(), bins=20, alpha=0.5)\n",
    "plt.hist(entropy_wrong.detach().cpu().numpy(), bins=20, alpha=0.5)\n",
    "plt.xlim(0.0,2.0)\n",
    "plt.title('Entropy (blue = correct predictions, orange = incorrect predictions)')\n",
    "plt.show()\n",
    "# plt.hist(amt_wrong.detach().cpu().numpy(), bins=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create connections to nodes\n",
    "# adj_vec =  torch.eye(adj.shape[0])[(labels == c).nonzero()[0:5]].sum(dim=0).squeeze() # 5 from class 5\n",
    "# adj_vec += torch.eye(adj.shape[0])[(labels == k).nonzero()[0:1]].sum(dim=0).squeeze() # 5 from class 5\n",
    "# adj_vec = torch.cat((adj_vec, torch.ones(1)))\n",
    "# adj_vec = (adj_vec / adj_vec.sum()).reshape(-1,1)\n",
    "\n",
    "# # Modify adjacency matrix\n",
    "# adj_ood = adj.to_dense()\n",
    "# adj_ood = torch.cat((torch.cat((adj_ood, adj_vec[:-1]), dim=1), adj_vec.t()), dim=0)\n",
    "# adj_ood = dense_to_sparse(adj_ood)len(idx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Synthetic\n",
    "# synthetic = [[1,1,1,1,1,1],\n",
    "#              [1,1,0,0,0,0],\n",
    "#              [1,0,1,0,0,0],\n",
    "#              [1,0,0,1,0,0],\n",
    "#              [1,0,0,0,1,0],\n",
    "#              [1,0,0,0,0,1],]\n",
    "# synthetic = torch.FloatTensor(synthetic)\n",
    "# synthetic = synthetic / synthetic.sum(dim=1, keepdim=True)\n",
    "# synthetic = dense_to_sparse(synthetic)\n",
    "\n",
    "# # Modify features\n",
    "# neighbor_feats  = feats[labels == n].mean(dim=0, keepdim=True)\n",
    "# node_feats      = feats[labels == m].mean(dim=0, keepdim=True)\n",
    "# synthetic_feats = [node_feats] + [neighbor_feats for _ in range(5)]\n",
    "# synthetic_feats = torch.cat(synthetic_feats, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
