{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "from torch.distributions.normal import Normal\n",
    "from torch.autograd import Variable\n",
    "    \n",
    "def softplus(rho):\n",
    "    # convert from rho -> sigma\n",
    "    return torch.log(1 + torch.exp(rho))     \n",
    "\n",
    "class GraphConvolution(Module):\n",
    "    \"\"\"\n",
    "    Simple GCN layer, similar to https://arxiv.org/abs/1609.02907\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.num_weights = 0\n",
    "        \n",
    "        self.weight = None # Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        self.num_weights += in_features * out_features\n",
    "        \n",
    "        if bias:\n",
    "            self.bias = None # Parameter(torch.FloatTensor(out_features))\n",
    "            self.num_weights += out_features\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "                    \n",
    "    def init_weights(self, weights):\n",
    "        self.weight = weights[:self.in_features * self.out_features].reshape(self.in_features, self.out_features)\n",
    "        if self.bias:\n",
    "            self.bias = weights[self.in_features * self.out_features:]\n",
    "        \n",
    "    def forward(self, input, adj):\n",
    "        support = torch.mm(input, self.weight)\n",
    "        output = torch.spmm(adj, support)\n",
    "        if self.bias is not None:\n",
    "            return output + self.bias\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "               + str(self.in_features) + ' -> ' \\\n",
    "               + str(self.out_features) + ')'\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, nfeat, nhid, nclass, dropout):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        self.gc1 = GraphConvolution(nfeat, nhid)\n",
    "        self.gc2 = GraphConvolution(nhid, nclass)\n",
    "        self.layers = [self.gc1, self.gc2]\n",
    "        self.num_weights = sum(layer.num_weights for layer in self.layers)\n",
    "        self.dropout = dropout\n",
    "        \n",
    "    def kernel(self, x):\n",
    "        ## Standard RBF kernel: x -> exp(-x*x)\n",
    "        return torch.exp(-x*x)\n",
    "    \n",
    "    def init_params(self):\n",
    "        return torch.rand(self.num_weights * 2, requires_grad=True) # stored as [mu1, mu2, rho1, rho2]\n",
    "    \n",
    "    def init_weights(self, var_params):\n",
    "        ## Returns log_prob of weights, prior_prob of weights\n",
    "        w_dist = Normal(var_params[:self.num_weights], softplus(var_params[self.num_weights:]))\n",
    "        p_dist = Normal(torch.zeros(self.num_weights), torch.ones(self.num_weights) * 5)\n",
    "        weights = w_dist.rsample()\n",
    "        \n",
    "        counter = 0\n",
    "        for layer in self.layers:\n",
    "            layer.init_weights(weights[counter:counter+layer.num_weights])\n",
    "            counter += layer.num_weights\n",
    "            \n",
    "        return w_dist.log_prob(weights), p_dist.log_prob(weights)\n",
    "        \n",
    "    def forward(self, x, adj):\n",
    "        x = self.kernel(self.gc1(x, adj))\n",
    "        # x = F.relu(self.gc1(x, adj))\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        x = self.gc2(x, adj)\n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'indices'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b76c3bde3bb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0madj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_cora\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/282_project/graph-project/gcn/dataloader.py\u001b[0m in \u001b[0;36mload_cora\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# Save for GAE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     torch.save({'adj_orig': adj_orig.todense(), 'adj_i': adj.indices, 'adj_v': adj.values,\n\u001b[0m\u001b[1;32m     50\u001b[0m                 \u001b[0;34m'adj_s'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'feats'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'labels'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 'idx_train': idx_train, 'idx_val': idx_val, 'idx_test': idx_test}, \n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'indices'"
     ]
    }
   ],
   "source": [
    "from dataloader import load_cora, load_adv_data\n",
    "\n",
    "# Load data\n",
    "adj, features, labels, idx_train, idx_val, idx_test = load_cora()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
